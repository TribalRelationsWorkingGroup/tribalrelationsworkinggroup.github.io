---
title: "2021-Spring-CSE151A-Introduction to AI: A Statistical Approach"
collection: teaching
type: "Undergraduate Class"
permalink: /teaching/2021-spring-CSE151A-StatisticalML
venue: "CSE, UCSD"
date: 2021-03-30
location: "La Jolla, CA"
---

**Class Time**: Tuesdays and Thursdays, 9:30AM to 10:50AM.  **Room**: [https://ucsd.zoom.us/j/93540989128](https://ucsd.zoom.us/j/93540989128).  **Piazza**: [https://piazza.com/class/kmmklfc6n0a32h](https://piazza.com/class/kmmklfc6n0a32h).


Online Lecturing
======

Due to the COVID-19, this course will be delivered over Zoom: [https://ucsd.zoom.us/j/93540989128](https://ucsd.zoom.us/j/93540989128)

Overview
======

This course mainly focuses on introducing machine learning methods and models that are useful in analyzing real-world data. It will cover classical regression & classification models, clustering methods, and deep neural networks. No previous background in machine learning is required, but all participants should be comfortable with programming, and with basic optimization and linear algebra. 

There is no textbook required, but here are some recommended readings:
- [The Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12.pdf) by Trevor Hastie, â€ŽRobert Tibshirani, and Jerome Friedman.
- [Data Mining: Concepts and Techniques](https://books.google.com/books/about/Data_Mining_Concepts_and_Techniques.html?id=pQws07tdpjoC&source=kp_book_description) by Jiawei Han et al.
- [Pattern Recognition and Machine Learning](https://books.google.com/books/about/Pattern_Recognition_and_Machine_Learning.html?id=HL4HrgEACAAJ&source=kp_book_description) by Christopher M. Bishop.
- [Dive into Deep Learning](https://d2l.ai/) book by Aston Zhang et al.

Prerequisites
======

1. Ability to code in Python: functions, control structures, string handling, arrays and dictionaries.

2. Familiarity with basic probability, at the level of CSE 21 or CSE 103.

3. Familiarity with basic linear algebra, at the level of Math 18 or Math 20F.

TAs and Tutors
======

- **Teaching Assistants**: 
- **Tutors**: 

Office Hours
======

- Jingbo Shang
    - Office Hour: Wednesdays, 10 to 11 AM
    - Zoom link: [https://ucsd.zoom.us/my/jshang](https://ucsd.zoom.us/my/jshang)

Note: all times are in **Pacific Time**.

Grading
======

- Homework: 20% each. Your lowest (of four) homework grades is dropped (or one homework can be skipped).
- Midterm: 40%.
- You should complete all work individually.
- Late submissions are NOT accepted.

Lecture Schedule
======

**Recording Note**: Please download the recording video for the full length. Dropbox website will only show you the first one hour.

**HW Note**: All HWs due before the lecture time 9:30 AM PT in the morning. 

(the schedule is tentative)

Week | Date        | Topic & Slides                                                  | Events
1    | 03/30 (Tue) | Introduction: Concepts and Evaluations | HW1 out
1    | 04/01 (Thu) | A Geometric View of Linear Algebra |
2    | 04/06 (Tue) | Nearest Neighbor Classification | HW1 due, HW2 out
2    | 04/08 (Thu) | Gradients and Optimization |
3    | 04/13 (Tue) | Least-Squares Regression, Logistic Regression, and Perceptron |
3    | 04/15 (Thu) | Overfitting and Regularization | 
4    | 04/20 (Tue) | Support Vector Machine (SVM) | HW2 due, HW3 out
4    | 04/22 (Thu) | SVM: Duality and Kernel |
5    | 04/27 (Tue) | K-Means Clustering & its Variants |
5    | 04/29 (Thu) | "Soft" Clustering: Gaussian Mixture |
6    | 05/04 (Tue) | Principle Component Analysis |
6    | 05/06 (Thu) | **Midterm** (no class, take-home, 24-hour) |
7    | 05/11 (Tue) | Naive Bayes and Decision Tree| HW3 due, HW4 out
7    | 05/13 (Thu) | Ensemble Learning: Bagging and Boosting |
8    | 05/18 (Tue) | Multi-class Classification |
8    | 05/20 (Thu) | Semi-supervised Learning |
9    | 05/25 (Tue) | Weakly-supervised Learning | 
9    | 05/27 (Thu) | Feed-forward Neural Networks | HW4 due
10   | 06/01 (Tue) | Convolutional Neural Networks |
10   | 06/03 (Thu) | Bias-Variance in Deep Neural Networks |


Homework (60%)
======

Your lowest (of four) homework grades is dropped (or one homework can be skipped).

- **HW1: Concepts and Evaluations (20%).** This homework mainly focuses on the machine learning concepts and how to evaluate different tasks.
- **HW2: KNN and Linear Models (20%).** This homework mainly focuses on nearest neighbor, least-square regression, logistic regression, and regularization.
- **HW3: SVM and Clustering (20%).** This homework mainly focuses on support vector machine, k-means, Gaussian Mixture, and PCA.
- **HW4: Ensemble Learning (20%).** This homework mainly focuses on decision tree, random forest, and AdaBoost.

Midterm (40%)
======

It is an open-book, take-home exam, which covers all lectures given before the Midterm. Most of the questions will be open-ended. Some of them might be slightly more difficult than homework. You will have 24 hours to complete the midterm, which is expected for about 2 hours.

- **Start**: May 6, 9:30 AM PT
- **End**: May 7, 9:30 AM PT
- Midterm problems download: TBD
- Please **make your submissions on Gradescope**.
